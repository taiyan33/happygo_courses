{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. detect_labels_uri( ) from vision.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START vision_label_detection_gcs]\n",
    "def detect_labels_uri(uri):\n",
    "    \"\"\"Detects labels in the file located in Google Cloud Storage or on the\n",
    "    Web.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    print('Labels:')\n",
    "\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "# [END vision_label_detection_gcs]\n",
    "\n",
    "## To be modified \n",
    "#     label_descriptions = []\n",
    "#     for label in labels:\n",
    "#         label_descriptions.append(label.description)\n",
    "#     return label_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. transcribe_gcs( ) from speech2text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START speech_transcribe_sync_gcs]\n",
    "def transcribe_gcs(language, gcs_uri):\n",
    "    \"\"\"Transcribes the audio file specified by the gcs_uri.\"\"\"\n",
    "    from google.cloud import speech\n",
    "    from google.cloud.speech import enums\n",
    "    from google.cloud.speech import types\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # [START speech_python_migration_config_gcs]\n",
    "    audio = types.RecognitionAudio(uri=gcs_uri)\n",
    "    config = types.RecognitionConfig(\n",
    "        # encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        # sample_rate_hertz=16000,\n",
    "        language_code=language)\n",
    "    # [END speech_python_migration_config_gcs]\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(u'Transcript: {}'.format(result.alternatives[0].transcript))\n",
    "# [END speech_transcribe_sync_gcs]\n",
    "    \n",
    "    \n",
    "    \n",
    "## To be modified    \n",
    "#     return response.results[0].alternatives[0].transcript\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. translate_text( ) from translate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import translate\n",
    "import six\n",
    "\n",
    "def translate_text(target, text):\n",
    "    # [START translate_translate_text]\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(\n",
    "        text, target_language=target)\n",
    "\n",
    "    print(u'Text: {}'.format(result['input']))\n",
    "    print(u'Translation: {}'.format(result['translatedText']))\n",
    "    print(u'Detected source language: {}'.format(\n",
    "        result['detectedSourceLanguage']))\n",
    "    # [END translate_translate_text]\n",
    "    \n",
    "## To be modified \n",
    "#     return result['translatedText']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. entities_text( ) from natural_language.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import six\n",
    "\n",
    "# [START language_entities_text]\n",
    "def entities_text(text):\n",
    "    \"\"\"Detects entities in the text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    # Instantiates a plain text document.\n",
    "    # [START language_python_migration_entities_text]\n",
    "    # [START language_python_migration_document_text]\n",
    "    document = types.Document(\n",
    "        content=text,\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "    # [END language_python_migration_document_text]\n",
    "\n",
    "    # Detects entities in the document. You can also analyze HTML with:\n",
    "    #   document.type == enums.Document.Type.HTML\n",
    "    entities = client.analyze_entities(document).entities\n",
    "\n",
    "    for entity in entities:\n",
    "        entity_type = enums.Entity.Type(entity.type)\n",
    "        print('=' * 20)\n",
    "        print(u'{:<16}: {}'.format('name', entity.name))\n",
    "        print(u'{:<16}: {}'.format('type', entity_type.name))\n",
    "        print(u'{:<16}: {}'.format('metadata', entity.metadata))\n",
    "        print(u'{:<16}: {}'.format('salience', entity.salience))\n",
    "        print(u'{:<16}: {}'.format('wikipedia_url',\n",
    "              entity.metadata.get('wikipedia_url', '-')))\n",
    "    # [END language_python_migration_entities_text]\n",
    "# [END language_entities_text]\n",
    "\n",
    "## To be modified   \n",
    "#     entity_names = []\n",
    "#     for entity in entities:\n",
    "#         entity_names.append(entity.name)\n",
    "#     return entity_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_audio_to_image(language, audio, image):\n",
    "    transcription = transcribe_gcs(language, audio)\n",
    "    translation = translate_text('en', transcription)   \n",
    "    entities = entities_text(translation)\n",
    "    labels = detect_labels_uri(image)\n",
    "    \n",
    "    has_match = False\n",
    "    for entity in entities:\n",
    "        if entity in labels:\n",
    "            print('The audio and image both contain: {}'.format(entity))\n",
    "            has_match = True\n",
    "    if not has_match:\n",
    "        print('The audio and image do not appear to be related.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The audio and image do not appear to be related.\n"
     ]
    }
   ],
   "source": [
    "compare_audio_to_image('de-DE', 'gs://ml-api-codelab/de-ostrich.wav', 'gs://ml-api-codelab/birds.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START language_syntax_text]\n",
    "def syntax_text(text):\n",
    "    \"\"\"Detects syntax in the text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    # Instantiates a plain text document.\n",
    "    # [START language_python_migration_syntax_text]\n",
    "    document = types.Document(\n",
    "        content=text,\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detects syntax in the document. You can also analyze HTML with:\n",
    "    #   document.type == enums.Document.Type.HTML\n",
    "    tokens = client.analyze_syntax(document).tokens\n",
    "\n",
    "    for token in tokens:\n",
    "        part_of_speech_tag = enums.PartOfSpeech.Tag(token.part_of_speech.tag)\n",
    "        print(u'{}: {}'.format(part_of_speech_tag.name,\n",
    "                               token.text.content))\n",
    "    # [END language_python_migration_syntax_text]\n",
    "# [END language_syntax_text]\n",
    "\n",
    "\n",
    "#     lemmas = ''\n",
    "#     for token in tokens:\n",
    "#         temp = token.lemma + ' '\n",
    "#         lemmas += temp\n",
    "#     return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tr-TR speech samples:\n",
    "\n",
    "gs://ml-api-codelab/tr-ball.wav\n",
    "\n",
    "gs://ml-api-codelab/tr-bike.wav\n",
    "\n",
    "gs://ml-api-codelab/tr-jacket.wav\n",
    "\n",
    "gs://ml-api-codelab/tr-ostrich.wav\n",
    "    \n",
    "\n",
    "### de-DE speech samples:\n",
    "\n",
    "gs://ml-api-codelab/de-ball.wav\n",
    "\n",
    "gs://ml-api-codelab/de-bike.wav\n",
    "\n",
    "gs://ml-api-codelab/de-jacket.wav\n",
    "\n",
    "gs://ml-api-codelab/de-ostrich.wav\n",
    "    \n",
    "\n",
    "### Image samples:\n",
    "\n",
    "gs://ml-api-codelab/bicycle.jpg\n",
    "\n",
    "gs://ml-api-codelab/birds.jpg\n",
    "\n",
    "gs://ml-api-codelab/coat_rack.jpg\n",
    "\n",
    "gs://ml-api-codelab/football.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
